{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIvhwE4zxX0s"
      },
      "outputs": [],
      "source": [
        "#Установка нужных пакетов\n",
        "!pip install --upgrade nltk gensim bokeh umap-learn\n",
        "\n",
        "import itertools\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import umap\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выгружаем датасет:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt -nc"
      ],
      "metadata": {
        "id": "hF9WPCtfxZR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379ac6c9-1d5b-4cca-e32a-fbe5527cbb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘./quora.txt’ already there; not retrieving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MaFpN9pvxtNg",
        "outputId": "4029be28-1a49-4e7f-c290-d37156f89f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(data[50]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvXRbOKGx0l_",
        "outputId": "a7728c17-884c-4f25-e20c-97f8514c38a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What', 'TV', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Задание 1: Перевести все слова в нижний регистр (NLTK) из data и добавьте как лист токенов в листе data_tok\n"
      ],
      "metadata": {
        "id": "ovkxi_QOySCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tok = []\n",
        "for line in data:\n",
        "  lst = [x.lower() for x in tokenizer.tokenize(line)]\n",
        "  data_tok.append(lst)\n",
        "\n",
        "\n",
        "#checking\n",
        "\n",
        "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(map(lambda l: not is_latin(l) or l.islower(), map(' '.join, data_tok))), \"please make sure to lowercase the data\"\n"
      ],
      "metadata": {
        "id": "EK7uvHi6zeWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Задание 2: Подсчитайте топ10 самых популярных лем в рамках data"
      ],
      "metadata": {
        "id": "dtKeoLCYzY4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "dict_words = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQyT29CADKqH",
        "outputId": "fae72978-b701-489b-d54e-cb06390a29dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_data_tok = [x for sublist in data_tok for x in sublist]"
      ],
      "metadata": {
        "id": "pRFoPjZt-yw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemm_lst = []\n",
        "for world in flatten_data_tok:\n",
        "  lemm_lst.append(lemmatizer.lemmatize(world))"
      ],
      "metadata": {
        "id": "tfb-rDSKDphG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Et85TjYkQ3Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lemm = Counter(lemm_lst)"
      ],
      "metadata": {
        "id": "q82sEV6nBDnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(count_lemm, orient='index')"
      ],
      "metadata": {
        "id": "_SB8VZWXQxzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(0).tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SC_OsL9dRmPP",
        "outputId": "06d0ba8b-5c99-4012-9386-4b174550e66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "of    112001\n",
              "how   135687\n",
              "in    139813\n",
              "to    141788\n",
              "i     149868\n",
              "a     172513\n",
              "is    185392\n",
              "what  214798\n",
              "the   252068\n",
              "?     552413"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7727c35-a151-4c98-9f08-4e222f06ba8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>112001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>135687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>139813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>141788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>149868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>172513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>185392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>214798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>252068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>?</th>\n",
              "      <td>552413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7727c35-a151-4c98-9f08-4e222f06ba8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7727c35-a151-4c98-9f08-4e222f06ba8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7727c35-a151-4c98-9f08-4e222f06ba8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Задание 3: Подсчитайте количество разных слов до и после лемматизации"
      ],
      "metadata": {
        "id": "a1SM3sn1zf1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(flatten_data_tok)) # до лематизации и стеминга"
      ],
      "metadata": {
        "id": "Q88BIteDzpWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9174e5-c453-4320-d43f-92b5d07b1482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87820"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(lemm_lst)) # после лематизации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDkxEBuFI2Fa",
        "outputId": "f3e25634-ab0c-47f9-8226-b347b7c8402a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80304"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Задание 4: Подсчитайте количество разных слов до и после стемминга"
      ],
      "metadata": {
        "id": "uxKa8yUUzqNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "x91DX51qzszR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "VNdi6KeYV-ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemm_lst = []\n",
        "for word in flatten_data_tok:\n",
        "  stemm_lst.append(stemmer.stem(word))"
      ],
      "metadata": {
        "id": "549rnfmzZkD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(stemm_lst)) # после стеминга"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qglwXrg5Z7Qi",
        "outputId": "c21e1aad-bb43-4b1b-de99-0a9dd7298642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67026"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Задание 5: Подсчитайте количество разных слов\n",
        "\n"
      ],
      "metadata": {
        "id": "XXA7Fe_izuqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemm_stemm_lst = []\n",
        "for word in lemm_lst:\n",
        "  lemm_stemm_lst.append(stemmer.stem(word))"
      ],
      "metadata": {
        "id": "BGgmHzUAzwqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemm_lemm_lst = []\n",
        "for word in stemm_lst:\n",
        "  stemm_lemm_lst.append(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "_HPXbWU2ayfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(lemm_stemm_lst)) # после леминга и затем стеминга"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj6JzII0bDmr",
        "outputId": "ef7be45a-5a73-49e3-87e1-bb54346ac907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66835"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(stemm_lemm_lst)) # после стеминга и затем леминга"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36fw1mTBbX4p",
        "outputId": "e51efdcb-df4f-4d93-ad9e-287b78b3a88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66818"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** при использовании стемминга вперед лематизации может потеряться часть уникальных слов, нужно делать сначала лематизацию а затем стемминг"
      ],
      "metadata": {
        "id": "jIm-5l6ReHCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGEXP\n",
        "\n",
        "https://www.programiz.com/python-programming/regex \n",
        "\n",
        "https://docs.python.org/3/howto/regex.html"
      ],
      "metadata": {
        "id": "At9iloRCVShn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern = 'a*s'\n",
        "test_string = 'abyss'\n",
        "result = re.match(pattern, test_string)\n",
        "\n",
        "if result:\n",
        "  print(\"Search successful.\")\n",
        "else:\n",
        "  print(\"Search unsuccessful.\")\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "521aLisyVUg_",
        "outputId": "a815bb20-bba8-48b9-cbc5-0968158a3c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search unsuccessful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern = '[a-zA-Z0-9]{0,20}@[a-z]{0,5}.[a-z]{0,3}'\n",
        "test_string = 'garafutdinov@list.ru'\n",
        "result = re.match(pattern, test_string)\n",
        "\n",
        "if result:\n",
        "  print(\"Search successful.\")\n",
        "else:\n",
        "  print(\"Search unsuccessful.\")\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cea138-dfb1-4caf-daab-83eaa52f7291",
        "id": "UtH9EIirOb9_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Задание 6: \n",
        "https://www.hackerrank.com/challenges/matching-specific-string/problem?isFullScreen=true \n",
        "\n",
        "###Задание 7: \n",
        "https://www.hackerrank.com/challenges/matching-whitespace-non-whitespace-character/problem?isFullScreen=true\n",
        "\n",
        "###Задание 8: \n",
        "https://www.hackerrank.com/challenges/matching-start-end/problem?isFullScreen=true\n",
        "\n",
        "###Задание 9: \n",
        "https://www.hackerrank.com/challenges/matching-word-boundaries/problem?isFullScreen=true"
      ],
      "metadata": {
        "id": "dH7qx_irU4Y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag Of Words (BOW)"
      ],
      "metadata": {
        "id": "Csv2YN2IRXJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(tokens):\n",
        "    ''' This function takes list of words in a sentence as input \n",
        "    and returns a vector of size of filtered_vocab.It puts 0 if the \n",
        "    word is not present in tokens and count of token if present.'''\n",
        "    vector=[]\n",
        "    for w in filtered_vocab:\n",
        "        vector.append(tokens.count(w))\n",
        "    return vector\n",
        "def unique(sequence):\n",
        "    '''This functions returns a list in which the order remains \n",
        "    same and no item repeats.Using the set() function does not \n",
        "    preserve the original ordering,so i didnt use that instead'''\n",
        "    seen = set()\n",
        "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
        "\n",
        "#create a list of stopwords.You can import stopwords from nltk too\n",
        "stopwords=[\"to\",\"is\",\"a\"]\n",
        "\n",
        "#list of special characters.You can use regular expressions too\n",
        "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
        "\n",
        "#Write the sentences in the corpus,in our case, just two \n",
        "string1=\"Welcome to Great Learning , Now start learning\"\n",
        "string2=\"Learning Learning is a good practice\"\n",
        "\n",
        "#convert them to lower case\n",
        "string1=string1.lower()\n",
        "string2=string2.lower()\n",
        "\n",
        "#split the sentences into tokens\n",
        "tokens1=string1.split()\n",
        "tokens2=string2.split()\n",
        "print(tokens1)\n",
        "print(tokens2)\n",
        "\n",
        "#create a vocabulary list\n",
        "vocab=unique(tokens1+tokens2)\n",
        "print(vocab)\n",
        "\n",
        "#filter the vocabulary list\n",
        "filtered_vocab=[]\n",
        "for w in vocab: \n",
        "    if w not in stopwords and w not in special_char: \n",
        "        filtered_vocab.append(w)\n",
        "print(filtered_vocab)\n",
        "\n",
        "#convert sentences into vectords\n",
        "vector1=vectorize(tokens1)\n",
        "print(vector1)\n",
        "vector2=vectorize(tokens2)\n",
        "print(vector2)"
      ],
      "metadata": {
        "id": "O8YWG3JhSFeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8603fe21-3926-48a2-8e4a-22692b676438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['welcome', 'to', 'great', 'learning', ',', 'now', 'start', 'learning']\n",
            "['learning', 'learning', 'is', 'a', 'good', 'practice']\n",
            "['welcome', 'to', 'great', 'learning', ',', 'now', 'start', 'is', 'a', 'good', 'practice']\n",
            "['welcome', 'great', 'learning', 'now', 'start', 'good', 'practice']\n",
            "[1, 1, 2, 1, 1, 0, 0]\n",
            "[0, 0, 2, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 10: Реализовать Bag of words на data_tok (можно на NLTK, можно без)"
      ],
      "metadata": {
        "id": "MOZ1qx05Q46b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first50 = ''\n",
        "for line in data[0:50]:\n",
        "  first50 += line\n",
        "first50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "xiYuO3xCLIB4",
        "outputId": "afdbb677-3703-4163-a82a-ddd15fa4afc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Can I get back with my ex even though she is pregnant with another guy's baby?\\nWhat are some ways to overcome a fast food addiction?\\nWho were the great Chinese soldiers and leaders who fought in WW2?\\nWhat are ZIP codes in the Bay Area?\\nWhy was George RR Martin critical of JK Rowling after losing the Hugo award?\\nWhat can I do to improve my immune system?\\nHow is your relationship with your mother in law?\\nHow does one get Free PSN codes/Vita Codes?\\nWhat is your review of osquery?\\nHow can I look smart and act smart?\\nWhich brand should go with the GTX 960 graphic card, MSI, Zotac or ASUS?\\nWhat is the ZIP code of India?\\nAs an Indian doctor practicing in my own private clinic. How can I earn more? What other sources of income can I use?\\nIs Windows the only OS that is not based on UNIX or Linux?\\nHow can I avoid using Facebook?\\nHow do you get a Norton Security renewal code?\\nDoes EMC plan a lightweight web client for Documentum?\\nWhere is the strangest place you've ever masturbated?\\nTamil Nadu, India: What can we learn from ex CM J.Jayalalitha?\\nWhich car should I buy out of Tiago, Kwid, Figo, Datsun or any other?\\nWho discovered plate tectonics and how?\\nIs the Earth the only planet that has life on it?\\nHow can I get a ride on a civilian C-130?\\nWhat does entertainment mean for you?\\nHow is the experience to be an extra on the show - How I Met Your Mother?\\nWill Windows run well enough to use Excel and Outlook in a VM on the new 2015 MacBook?\\nIs it true that Ancient China had no glass? Or was it no clear glass? Or not?\\nWhat is your review of iPad Mini 2?\\nWhat is the purpose of steam turbine?\\nWhen do you really need to create an abstract class?\\nHow are Dalmatian dogs like as pets?\\nAre drivers within rich countries less likely to slow down when they see a driver's turn signal?\\nAre Asian girls attracted to black guys?\\nFrom where can I buy castor oil for hair in Mumbai?\\nDoes CVS still develop film? Why or why not?\\nCan China always print money?\\nWhat is fake software?\\nHow do students at IIT get foreign internships?\\nHow do I find my life's goal?\\nWhat are the Upcoming mobiles?\\nWhat is the chemical formula for hydrochloric acid?\\nWhich is the biggest Disneyland in the world? What is the best way to get entrance tickets for it?\\nHow does the finance credit score work?\\nHow do I meet foreign guys in Hong Kong?\\nIs the ATM business still viable?\\nHow can I learn to speak English well in non-English environment?\\nCan a high school student get an internship at Goldman Sachs?\\nWho are the top business coaches in Australia?\\nWhy do Girls wait for Boys to Propose?\\nShould cricket be our national sport and not hockey?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r2rz3XFOlHN",
        "outputId": "2193f5c6-ed72-4c6f-a60a-7e1099d0cfe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TextPreproc (text: str, uniqs: bool=True):\n",
        "  '''This function processes the incoming text: \n",
        "  tokenizes, removes punctuation and stop words, lemmatizes. \n",
        "  Returns a list of processed гтшйгуwords.'''\n",
        "  text = text.lower()\n",
        "  tokens_text = tokenizer.tokenize(text)\n",
        "  words = [word for word in tokens_text if word.isalpha()]\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  func_lem = lambda w: lemmatizer.lemmatize(w)\n",
        "  lem_words = list(map(func_lem, words))\n",
        "\n",
        "  return (set(lem_words) if uniqs else lem_words)"
      ],
      "metadata": {
        "id": "FS4YavBCXeah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(TextPreproc(first50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRIaZK0AbTKo",
        "outputId": "9298a7b4-0a99-416d-9270-f645bd9672e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "213"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** размер bag of words для 50 первых строк qoura после удаления стопслов и лематизации равен 213"
      ],
      "metadata": {
        "id": "lfDapsHxVaCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дополнительное задание. Найти наиболее близкие вектора/строки среди первых 50 строк quora"
      ],
      "metadata": {
        "id": "X6xWYEqsvLHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TextPreproc(first50)"
      ],
      "metadata": {
        "id": "jQPXkt-vUsPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = []\n",
        "for line in data[0:50]:\n",
        "  prepoc_line = TextPreproc(line, False)\n",
        "  temp_vector = []\n",
        "  for i in vector:\n",
        "    if i in prepoc_line:\n",
        "      temp_vector.append(1)\n",
        "    else:\n",
        "      temp_vector.append(0)\n",
        "  matrix.append(temp_vector)"
      ],
      "metadata": {
        "id": "7xR7Nu21dL-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "cM0JuWZth7-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(matrix).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mPj3DK2iofx",
        "outputId": "8192c640-515e-4ee3-8d54-1e4a73c90cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 213)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_i_j = [0, 0, 0]\n",
        "for i in range(len(matrix)-1):\n",
        "  for j in range(i+1, len(matrix)):\n",
        "    a = matrix[i]\n",
        "    b = matrix[j]\n",
        "    cos_sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    if cos_sim > cos_i_j[0]:\n",
        "      cos_i_j = [cos_sim, i, j]\n",
        "print(cos_i_j[0])\n",
        "print(cos_i_j[1], data[cos_i_j[1]])\n",
        "print(cos_i_j[2], data[cos_i_j[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1_TFTbWi7hz",
        "outputId": "8ab6282c-02c0-4676-dce6-459dcd532a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5773502691896258\n",
            "3 What are ZIP codes in the Bay Area?\n",
            "\n",
            "11 What is the ZIP code of India?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** наиболее близкие строки под номером 3 и 11."
      ],
      "metadata": {
        "id": "Ow1jYv-cvmZY"
      }
    }
  ]
}